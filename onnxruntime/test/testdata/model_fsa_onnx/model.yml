_name: null
common:
  _name: null
  no_progress_bar: false
  log_interval: 100
  log_format: null
  log_file: null
  aim_repo: null
  aim_run_hash: null
  tensorboard_logdir: null
  wandb_project: null
  azureml_logging: false
  seed: 1
  cpu: false
  tpu: false
  bf16: false
  tf32: false
  memory_efficient_bf16: false
  fp16: false
  memory_efficient_fp16: false
  fp16_no_flatten_grads: false
  fp16_init_scale: 128
  fp16_scale_window: null
  fp16_scale_tolerance: 0.0
  on_cpu_convert_precision: false
  min_loss_scale: 0.0001
  threshold_loss_scale: null
  amp: false
  amp_batch_retries: 2
  amp_init_scale: 128
  amp_scale_window: null
  user_dir: nuance/nuance_src
  empty_cache_freq: 0
  all_gather_list_size: 16384
  model_parallel_size: 1
  quantization_config_path: null
  profile: false
  reset_logging: false
  suppress_crashes: false
  use_plasma_view: false
  plasma_path: /tmp/plasma
  raise_oom: true
  deepspeed: false
  deepspeed_config: null
  compile_model: false
  export_format: onnx
common_eval:
  _name: null
  path: null
  post_process: null
  quiet: false
  model_overrides: '{}'
  results_path: null
distributed_training:
  _name: null
  distributed_world_size: 1
  distributed_num_procs: 1
  distributed_rank: 0
  distributed_backend: nccl
  distributed_init_method: null
  distributed_port: -1
  device_id: 0
  distributed_no_spawn: false
  ddp_backend: pytorch_ddp
  ddp_comm_hook: none
  bucket_cap_mb: 25
  fix_batches_to_gpus: false
  find_unused_parameters: false
  gradient_as_bucket_view: false
  fast_stat_sync: false
  heartbeat_timeout: -1
  broadcast_buffers: false
  slowmo_momentum: null
  slowmo_base_algorithm: localsgd
  localsgd_frequency: 3
  nprocs_per_node: 1
  pipeline_model_parallel: false
  pipeline_balance: null
  pipeline_devices: null
  pipeline_chunks: 0
  pipeline_encoder_balance: null
  pipeline_encoder_devices: null
  pipeline_decoder_balance: null
  pipeline_decoder_devices: null
  pipeline_checkpoint: never
  zero_sharding: none
  fp16: false
  memory_efficient_fp16: false
  tpu: false
  no_reshard_after_forward: false
  fp32_reduce_scatter: false
  cpu_offload: false
  use_sharded_state: false
  not_fsdp_flatten_parameters: false
dataset:
  _name: null
  num_workers: 1
  skip_invalid_size_inputs_valid_test: false
  max_tokens: 10
  batch_size: 1
  required_batch_size_multiple: 8
  required_seq_len_multiple: 1
  dataset_impl: null
  data_buffer_size: 10
  train_subset: train
  valid_subset: valid
  combine_valid_subsets: null
  ignore_unused_valid_subsets: false
  validate_interval: 1
  validate_interval_updates: 0
  validate_after_updates: 0
  fixed_validation_seed: null
  disable_validation: false
  max_tokens_valid: 10
  batch_size_valid: 1
  max_valid_steps: null
  curriculum: 0
  gen_subset: test
  num_shards: 1
  shard_id: 0
  grouped_shuffling: false
  update_epoch_batch_itr: false
  update_ordered_indices_seed: false
optimization:
  _name: null
  max_epoch: 0
  max_update: 10
  stop_time_hours: 0.0
  clip_norm: 0.0
  sentence_avg: false
  update_freq:
  - 1
  lr:
  - 0.0001
  stop_min_lr: -1.0
  use_bmuf: false
  skip_remainder_batch: false
checkpoint:
  _name: null
  save_dir: /work/tmp6nu78h7r
  restore_file: checkpoint_last.pt
  continue_once: null
  finetune_from_model: null
  reset_dataloader: false
  reset_lr_scheduler: false
  reset_meters: false
  reset_optimizer: false
  optimizer_overrides: '{}'
  save_interval: 1
  save_interval_updates: 5
  keep_interval_updates: -1
  keep_interval_updates_pattern: -1
  keep_last_epochs: -1
  keep_best_checkpoints: -1
  no_save: false
  no_epoch_checkpoints: true
  no_last_checkpoints: false
  no_save_optimizer_state: false
  save_optimizer_ckpt_last_only: false
  best_checkpoint_metric: loss
  maximize_best_checkpoint_metric: false
  patience: -1
  checkpoint_suffix: ''
  checkpoint_shard_count: 1
  load_checkpoint_on_all_dp_ranks: false
  write_checkpoints_asynchronously: false
  model_parallel_size: 1
bmuf:
  _name: null
  block_lr: 1.0
  block_momentum: 0.875
  global_sync_iter: 50
  warmup_iterations: 500
  use_nbm: false
  average_sync: false
  distributed_world_size: 1
generation:
  _name: null
  beam: 3
  beam_mt: 0
  nbest: 1
  max_len_a: 0.0
  max_len_b: 10
  max_len_a_mt: 0.0
  max_len_b_mt: 200
  min_len: 1
  match_source_len: false
  unnormalized: false
  no_early_stop: false
  no_beamable_mm: false
  lenpen: 1.0
  lenpen_mt: 1.0
  unkpen: 0.0
  replace_unk: null
  sacrebleu: false
  score_reference: false
  score_nbests: false
  prefix_size: 0
  no_repeat_ngram_size:
  - 3
  no_repeat_ngram_history_a: 0
  no_repeat_ngram_history_b: -1
  no_repeat_ngram_format_tokens: ''
  no_repeat_ngram_format_mode: simple
  sampling: false
  sampling_topk: -1
  sampling_topp: -1.0
  constraints: null
  temperature: 1.0
  sequence_temperature: 1.0
  diverse_beam_groups: -1
  diverse_beam_strength: 0.5
  diversity_rate: -1.0
  print_alignment: null
  print_alignment_eps: 0.0
  print_step: false
  lm_path: null
  lm_weight: 0.0
  ensemble_linear_weights: ''
  ensemble_log_linear_weights: ''
  iter_decode_eos_penalty: 0.0
  iter_decode_max_iter: 10
  iter_decode_force_max_iter: false
  iter_decode_with_beam: 1
  iter_decode_with_external_reranker: false
  retain_iter_history: false
  retain_dropout: false
  retain_dropout_modules: null
  decoding_format: null
  no_seed_provided: true
  eos_token: null
  chunked_decoding_max_len: 0
  chunked_decoding_simulate_disabled: false
  chunked_decoding_initial_state: null
  chunked_decoding_output_state: ''
  chunked_decoding_prefix_chunk_size: 0
  skip_decoding: false
  fsa_path: /home/azureuser/tools/fairseq/nuance/nuance_src/tests/fsa/test_grammar_interactive.yaml
  fsa_lprobs_boost: 1.0
  fsa_eos_constraint: false
  fsa_partial_decoding: false
eval_lm:
  _name: null
  output_word_probs: false
  output_word_stats: false
  context_window: 0
  softmax_batch: 9223372036854775807
interactive:
  _name: null
  buffer_size: 0
  input: '-'
model:
  no_progress_bar: true
  log_interval: 5
  log_format: simple
  log_file: null
  aim_repo: null
  aim_run_hash: null
  tensorboard_logdir: null
  wandb_project: null
  azureml_logging: false
  seed: 1
  cpu: true
  tpu: false
  bf16: false
  tf32: false
  memory_efficient_bf16: false
  fp16: false
  memory_efficient_fp16: false
  fp16_no_flatten_grads: false
  fp16_init_scale: 128
  fp16_scale_window: null
  fp16_scale_tolerance: 0.0
  on_cpu_convert_precision: false
  min_loss_scale: 0.0001
  threshold_loss_scale: null
  amp: false
  amp_batch_retries: 2
  amp_init_scale: 128
  amp_scale_window: null
  user_dir: null
  empty_cache_freq: 0
  all_gather_list_size: 16384
  model_parallel_size: 1
  quantization_config_path: null
  profile: false
  reset_logging: false
  suppress_crashes: false
  use_plasma_view: false
  plasma_path: /tmp/plasma
  raise_oom: true
  deepspeed: false
  deepspeed_config: null
  criterion: cross_entropy
  tokenizer: null
  bpe: null
  optimizer: adam
  lr_scheduler: fixed
  simul_type: null
  scoring: bleu
  task: nuance_translation
  num_workers: 1
  skip_invalid_size_inputs_valid_test: false
  max_tokens: 10
  batch_size: null
  required_batch_size_multiple: 1
  required_seq_len_multiple: 1
  dataset_impl: null
  data_buffer_size: 10
  train_subset: train
  valid_subset: valid
  combine_valid_subsets: null
  ignore_unused_valid_subsets: false
  validate_interval: 1
  validate_interval_updates: 0
  validate_after_updates: 0
  fixed_validation_seed: null
  disable_validation: false
  max_tokens_valid: 10
  batch_size_valid: null
  max_valid_steps: null
  curriculum: 0
  gen_subset: test
  num_shards: 1
  shard_id: 0
  grouped_shuffling: false
  update_epoch_batch_itr: false
  update_ordered_indices_seed: false
  distributed_world_size: 1
  distributed_num_procs: 1
  distributed_rank: 0
  distributed_backend: nccl
  distributed_init_method: null
  distributed_port: -1
  device_id: 0
  distributed_no_spawn: false
  ddp_backend: pytorch_ddp
  ddp_comm_hook: none
  bucket_cap_mb: 25
  fix_batches_to_gpus: false
  find_unused_parameters: false
  gradient_as_bucket_view: false
  fast_stat_sync: false
  heartbeat_timeout: -1
  broadcast_buffers: false
  slowmo_momentum: null
  slowmo_base_algorithm: localsgd
  localsgd_frequency: 3
  nprocs_per_node: 1
  pipeline_model_parallel: false
  pipeline_balance: null
  pipeline_devices: null
  pipeline_chunks: 0
  pipeline_encoder_balance: null
  pipeline_encoder_devices: null
  pipeline_decoder_balance: null
  pipeline_decoder_devices: null
  pipeline_checkpoint: never
  zero_sharding: none
  no_reshard_after_forward: false
  fp32_reduce_scatter: false
  cpu_offload: false
  use_sharded_state: false
  not_fsdp_flatten_parameters: false
  arch: nuance_transformer_pointer_generator_vaswani_wmt_en_fr_big
  max_epoch: 0
  max_update: 10
  stop_time_hours: 0
  clip_norm: 0.0
  sentence_avg: false
  update_freq:
  - 1
  lr:
  - 0.0001
  stop_min_lr: -1.0
  use_bmuf: false
  skip_remainder_batch: false
  save_dir: /work/tmp6nu78h7r
  restore_file: checkpoint_last.pt
  continue_once: null
  finetune_from_model: null
  reset_dataloader: false
  reset_lr_scheduler: false
  reset_meters: false
  reset_optimizer: false
  optimizer_overrides: '{}'
  save_interval: 1
  save_interval_updates: 5
  keep_interval_updates: -1
  keep_interval_updates_pattern: -1
  keep_last_epochs: -1
  keep_best_checkpoints: -1
  no_save: false
  no_epoch_checkpoints: true
  no_last_checkpoints: false
  no_save_optimizer_state: false
  save_optimizer_ckpt_last_only: false
  best_checkpoint_metric: loss
  maximize_best_checkpoint_metric: false
  patience: -1
  checkpoint_suffix: ''
  checkpoint_shard_count: 1
  load_checkpoint_on_all_dp_ranks: false
  write_checkpoints_asynchronously: false
  store_ema: false
  ema_decay: 0.9999
  ema_start_update: 0
  ema_seed_model: null
  ema_update_freq: 1
  ema_fp32: false
  force_generation: null
  chunk_encoder_sizes: null
  chunk_encoder_min_lens: null
  chunk_encoder_shifts: ''
  chunk_encoder_overlaps: null
  chunk_encoder_by_masks: false
  chunk_encoder_ignore_length: false
  chunk_encoder_types: null
  efficient_short_chunks: false
  decoder_activation_fn: null
  decoder_flash_attn_std: 0.0
  encoder_flash_attn_std: 0.0
  decoder_flash_xattn_std: 0.0
  decoder_flash_attn_eps: 0.0
  encoder_flash_attn_eps: 0.0
  decoder_flash_xattn_eps: 0.0
  encoder_rotative_embedding: '-1'
  decoder_rotative_embedding: null
  encoder_rotative_period: 22000
  decoder_rotative_period: 22000
  use_relative_pos_embeddings: false
  use_scalar_rel_pos: false
  decoder_use_scalar_rel_pos: false
  max_relative_pos: 1024
  heads_share_embeddings: false
  add_pos_embeddings_to_values: false
  rel_pos_encoder_layers: ''
  rel_pos_decoder_layers: ''
  scalar_rel_pos_num_buckets: 128
  attn_grp_size_encoder_layers: '1'
  attn_grp_reshape_encoder_layers: '1'
  attn_grp_relpos_firstpos: false
  phrase_augment_time_protect: null
  phrase_augment_time_protect_rel: null
  phrase_augment_time_width: null
  phrase_augment_time_width_rel: null
  phrase_augment_time_width_max: null
  phrase_augment_time_num: null
  phrase_augment_time_num_rel: null
  phrase_augment_time_num_max: null
  phrase_augment_encoder_layers: ''
  phrase_augment_renormalize: false
  drop_dim_width: null
  drop_dim_width_rel: null
  drop_dim_width_max: null
  drop_dim_num: null
  drop_dim_num_rel: null
  drop_dim_num_max: null
  drop_dim_renormalize: false
  drop_dim_encoder_layers: ''
  encoder_gaussian_noise: '0.0'
  decoder_gaussian_noise: '0.0'
  data: /home/miguel_delagua/repos/fairseq_update/nuance/nuance_src/tests/binary_data
  source_lang: src
  target_lang: tgt
  load_alignments: false
  left_pad_source: false
  left_pad_target: false
  upsample_primary: -1
  truncate_source: false
  num_batch_buckets: 0
  eval_bleu: false
  eval_bleu_args: '{}'
  eval_bleu_detok: space
  eval_bleu_detok_args: '{}'
  eval_tokenized_bleu: false
  eval_bleu_remove_bpe: null
  eval_bleu_print_samples: false
  right_pad_source: true
  load_masks: false
  target_mask_scale: 0.1
  target_mask_ntokens: false
  attention_out: null
  prefix_with_target: false
  stop_after_prefix: false
  prefix_size: 0
  word_dropout: 0.0
  load_negative_examples: false
  target_negative_score_scale: 0
  adam_betas:
  - 0.9
  - 0.999
  adam_eps: 1.0e-08
  weight_decay: 0.0
  use_old_adam: false
  fp16_adam_stats: false
  force_anneal: null
  lr_shrink: 0.1
  warmup_updates: 0
  pad: 1
  eos: 2
  unk: 3
  alignment_layer: 0
  alignment_heads: 1
  source_position_markers: 0
  encoder_flash_attn: true
  encoder_flash_attn_shadow_infer: true
  encoder_attention_heads: 2
  encoder_embed_dim: 32
  encoder_ffn_embed_dim: 64
  encoder_layers: 1
  encoder_normalize_before: true
  decoder_attention_heads: 2
  decoder_embed_dim: 32
  decoder_ffn_embed_dim: 64
  decoder_layers: 1
  share_all_embeddings: true
  max_source_positions: 10
  max_target_positions: 10
  no_seed_provided: false
  dropout: 0.1
  encoder_embed_path: null
  encoder_learned_pos: false
  decoder_embed_path: null
  decoder_normalize_before: false
  decoder_learned_pos: false
  attention_dropout: 0.0
  activation_dropout: 0.0
  activation_fn: relu
  adaptive_softmax_cutoff: null
  adaptive_softmax_dropout: 0
  share_decoder_input_output_embed: true
  merge_src_tgt_embed: false
  no_token_positional_embeddings: false
  adaptive_input: false
  no_cross_attention: false
  cross_self_attention: false
  decoder_output_dim: 32
  decoder_input_dim: 32
  no_scale_embedding: false
  layernorm_embedding: false
  tie_adaptive_weights: false
  checkpoint_activations: false
  offload_activations: false
  encoder_layers_to_keep: null
  decoder_layers_to_keep: null
  encoder_layerdrop: 0
  decoder_layerdrop: 0
  quant_noise_pq: 0
  quant_noise_pq_block_size: 8
  quant_noise_scalar: 0
  _name: nuance_transformer_pointer_generator_vaswani_wmt_en_fr_big
  nuance_activation_fn: relu
  nuance_decoder_activation_fn: relu
  export: true
task:
  _name: nuance_translation
  data: /home/azureuser/tools/fairseq/tmp
  source_lang: src
  target_lang: tgt
  load_alignments: false
  left_pad_source: false
  left_pad_target: false
  max_source_positions: 10
  max_target_positions: 10
  upsample_primary: -1
  truncate_source: false
  num_batch_buckets: 0
  train_subset: train
  dataset_impl: null
  required_seq_len_multiple: 1
  eval_bleu: false
  eval_bleu_args: '{}'
  eval_bleu_detok: space
  eval_bleu_detok_args: '{}'
  eval_tokenized_bleu: false
  eval_bleu_remove_bpe: null
  eval_bleu_print_samples: false
  right_pad_source: true
  load_masks: false
  target_mask_scale: 0.1
  target_mask_ntokens: false
  attention_out: null
  prefix_with_target: false
  stop_after_prefix: false
  prefix_size: 0
  word_dropout: 0.0
  load_negative_examples: false
  target_negative_score_scale: 0
criterion:
  _name: cross_entropy
  sentence_avg: false
optimizer:
  _name: adam
  adam_betas:
  - 0.9
  - 0.999
  adam_eps: 1.0e-08
  weight_decay: 0.0
  use_old_adam: false
  fp16_adam_stats: false
  tpu: false
  lr:
  - 0.0001
lr_scheduler:
  _name: fixed
  force_anneal: null
  lr_shrink: 0.1
  warmup_updates: 0
  lr:
  - 0.0001
scoring:
  _name: bleu
  pad: 1
  eos: 2
  unk: 3
bpe: null
tokenizer: null
ema:
  _name: null
  store_ema: false
  ema_decay: 0.9999
  ema_start_update: 0
  ema_seed_model: null
  ema_update_freq: 1
  ema_fp32: false
simul_type: null
